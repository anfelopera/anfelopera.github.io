{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian processes – spatial regression (Python version)\n",
    "GMM, INSA Toulouse, France <br />\n",
    "Andrés F. López-Lopera, ONERA-DTIS <br />\n",
    "May 2021\n",
    "<br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab session, you are free to use the language of your choice (e.g. R or Python). In this notebook we propose Python implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading useful toolboxes\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D spatial GP regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical session, we consider spatial data. We generate first some 2D synthetic data from a centred spatial GP with covariance function given by:\n",
    "\n",
    "$$k(\\textbf{x},\\textbf{y}) = \\sigma^2 \\exp\\left( - \\frac{(x_1-y_1)^2}{2 \\theta_1^2} - \\frac{(x_2-y_2)^2}{2 \\theta_2^2}\\right),$$\n",
    "\n",
    "with $\\textbf{x} = (x_1, x_2) \\in \\mathbb{R}^2$ and $\\textbf{y} = (y_1, y_2) \\in \\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** For a grid of 30x30 points on $[0, 1]^2$, simulate a GP realisation using the function ``np.random.multivariate_normal`` and considering the variance parameter $\\sigma^2 = 1$ and the length-scale parameters $\\theta_1 = \\theta_2 = 0.2$. Display the resulting 2D SE kernel and the generated GP sample (2D and 3D visualisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating synthetic data from a GP\n",
    "def SEkernel2D(x, y, param): # 2D squared exponential kernel\n",
    "    \"\"\" 2D Squared exponential kernel\n",
    "    input:\n",
    "      x,y: input vectors\n",
    "      param: parameters (sigma,theta1,theta2)\n",
    "    output:\n",
    "      covariance matrix cov(x,y)\n",
    "    \"\"\"\n",
    "    sigma2, theta1, theta2 = param[0], param[1], param[2]\n",
    "    dist1 = # to complete\n",
    "    dist2 = # to complete\n",
    "    return sigma2*np.exp(-0.5*(dist1**2 + dist2**2))\n",
    "\n",
    "n = 30 # number of points per input dimension\n",
    "n_total = n**2 # total number of points\n",
    "x = np.linspace(0, 1, n) \n",
    "x2, x1 = np.meshgrid(x,x) # generating an equispaced 2D grid\n",
    "X = np.concatenate((x1.reshape(-1,1), x2.reshape(-1,1)), axis=1) # 2D grid\n",
    "param = [1, 0.2, 0.2] # covariance parameters\n",
    "kern = # to complete\n",
    "\n",
    "# sampling from the resulting GP\n",
    "np.random.seed(0) # a seed for reproducibility\n",
    "y = # to complete\n",
    "\n",
    "# plotting the results\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "ax = fig.add_subplot(131)\n",
    "plt.contourf(kern)\n",
    "plt.xlabel(\"$x$\"); plt.ylabel(\"$x'$\"); plt.title(\"2D SE kernel\")\n",
    "\n",
    "ax = fig.add_subplot(132, projection='3d')\n",
    "ax.plot_surface(x, x, y.reshape(n, n), rstride=1, cstride=1,\n",
    "                edgecolor='none', alpha=0.3)\n",
    "plt.xlim(-0.1, 1.1), plt.ylim(-0.1, 1.1)\n",
    "ax.set_xlabel(r'$x_1$'); ax.set_ylabel(r'$x_2$'); ax.set_zlabel(r'$y$');\n",
    "ax.set_title(\"GP sample - 3D visualisation\")\n",
    "\n",
    "ax = fig.add_subplot(133)\n",
    "cf = ax.pcolormesh(x, x, y.reshape(n, n), shading='auto')\n",
    "ax.set_xlabel(r'$x_1$')\n",
    "ax.set_ylabel(r'$x_2$')\n",
    "ax.set_title(r'$y$ (2D visualisation)')\n",
    "fig.colorbar(cf, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Repeat the procedure in **Question 1** but changing the values of $\\sigma^2, \\theta_1$ and $\\theta_2$. What can you observe?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** For instance, consider $\\sigma^2 = 1$ and $\\theta_1 = \\theta_2 = 0.2$. In real-world applications, we commonly have acces to a few amount of training data and we aim at predicting values at new points. Split the data in two subsets: one containing the training data and the other one containing the test data. Use the command ``np.random.permutation`` in order to generate a random permutation with ``n_total`` points. Then, take the first 1% of indexes of the permutation for constructing the training set. The remaining indexes are used for building up the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting data into a training set and a test set\n",
    "# generating a random permutation with n_total points\n",
    "np.random.seed(2)\n",
    "idx = # to complete\n",
    "\n",
    "# taking a proportion of the permuted indexes for defining the training dataset\n",
    "prop_train = 0.01\n",
    "n_train = int(np.ceil(prop_train * n_total))\n",
    "X_train = X[idx[:n_train], :]\n",
    "y_train = y[idx[:n_train]]\n",
    "\n",
    "# using the remaining indexes for constructing the test dataset\n",
    "X_test = X[idx[n_train:], :]\n",
    "y_test = y[idx[n_train:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** With the help of the ``KRG`` function from the ``smt`` toolbox, construct a GP regression model (also known as a Kriging model in geostatistics) using a squared exponential kernel function. You can see the documentation in https://smt.readthedocs.io/en/latest/_src_docs/surrogate_models/krg.html for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smt.surrogate_models import KRG\n",
    "\n",
    "# defining the kriging model\n",
    "sm = # to complete\n",
    "# passing the training data to the KRG model\n",
    "sm.set_training_values(X_train, y_train)\n",
    "# training the model\n",
    "sm.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Use the resulting GP model to predict values at some points: either at the training points or at the test points. Compute an error criterion based on the MSE for both prediction results. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions at new points\n",
    "pred_train = # to complete\n",
    "pred_test = # to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = # to complete\n",
    "rmse_test = # to complete\n",
    "print(\"RMSE - training data:\", rmse_train)\n",
    "print(\"RMSE - test data:\", rmse_test)\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(y_train, pred_train, \".\")\n",
    "ax.plot([np.min(y_train), np.max(y_train)],\n",
    "        [np.min(pred_train),np.max(pred_train)], \"--\")\n",
    "ax.set_xlabel(\"true values\"); ax.set_ylabel(\"prediction\")\n",
    "ax.set_title(\"training data - RMSE: %.3f\" % rmse_train)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(y_test, pred_test, \".\")\n",
    "ax.plot([np.min(y_test), np.max(y_test)],\n",
    "        [np.min(pred_test),np.max(pred_test)], \"--\")\n",
    "ax.set_xlabel(\"true values\")\n",
    "ax.set_ylabel(\"prediction\")\n",
    "ax.set_title(\"test data - RMSE: %.3f\" % rmse_test);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Some conclusions here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Use the resulting GP model to predict values at the entire domain $[0,1]^2$. Display 2D and 3D visualisations of the target profile, the predicted GP mean and the predictive GP variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = # to complete\n",
    "var_all = # to complete\n",
    "\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "ax = fig.add_subplot(131, projection='3d')\n",
    "ax.plot_surface(x, x, y.reshape(n,n), rstride=1, cstride=1,\n",
    "                edgecolor='none', alpha=0.3)\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "ax.set_xlabel(r'$x_1$')\n",
    "ax.set_ylabel(r'$x_2$')\n",
    "ax.set_zlabel(r'$y$');\n",
    "\n",
    "ax = fig.add_subplot(132, projection='3d')\n",
    "ax.plot_surface(x, x, pred_all.reshape(n,n), rstride=1, cstride=1,\n",
    "                edgecolor='none', alpha=0.3, color=\"C1\")\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "ax.set_xlabel(r'$x_1$')\n",
    "ax.set_ylabel(r'$x_2$')\n",
    "ax.set_zlabel(\"predictive mean\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "ax = fig.add_subplot(131)\n",
    "cf = ax.pcolormesh(x, x, y.reshape(n,n), shading='auto')\n",
    "ax.set_xlabel(r'$x_1$')\n",
    "ax.set_ylabel(r'$x_2$')\n",
    "ax.set_title(r'$y$')\n",
    "fig.colorbar(cf, ax=ax);\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "cf = ax.pcolormesh(x, x, pred_all.reshape(n,n), shading='auto')\n",
    "ax.plot(X_train[:,0], X_train[:,1], \"k.\")\n",
    "ax.set_xlabel(r'$x_1$')\n",
    "ax.set_ylabel(r'$x_2$')\n",
    "ax.set_title(\"predictive mean\")\n",
    "fig.colorbar(cf, ax=ax);\n",
    "\n",
    "ax = fig.add_subplot(133)\n",
    "cf = ax.pcolormesh(x, x, var_all.reshape(n,n), shading='auto')\n",
    "ax.plot(X_train[:,0], X_train[:,1], \"k.\")\n",
    "ax.set_xlabel(r'$x_1$')\n",
    "ax.set_ylabel(r'$x_2$')\n",
    "ax.set_title(\"predictive variance\")\n",
    "fig.colorbar(cf, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Repeat the procedure from **Questions 1-6** but changing the covariance function, the covariance parameters $\\sigma^2, \\theta_1, \\theta_2$, the seed of the the randomState, the percentage of training data, etc. What can you conclude?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus.** Using a 2D dataset of your choice (see https://archive.ics.uci.edu/ml/datasets.php for some examples), repeat the procedure from **Questions 3-6**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
